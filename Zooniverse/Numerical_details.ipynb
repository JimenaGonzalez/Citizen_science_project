{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65490fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de499ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Rojas:  0.006727251\n",
      "Highest Jacobs:  0.0033\n",
      "Highest Gonzalez:  0.001\n"
     ]
    }
   ],
   "source": [
    "#Maximum score of the sample with 80% of the lowest scores\n",
    "\n",
    "filepath = '/Users/jimenagonzalez/research/DSPL/Citizen_science_project/Intersection/'\n",
    "data_inter = pd.read_csv(filepath + 'intersection.csv')\n",
    "data_inter = data_inter.dropna()  # Remove rows with NaN values\n",
    "data_inter = data_inter.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "#80% of len(data_inter) is 602578\n",
    "\n",
    "data_inter.sort_values(by='K_SCORE', inplace=True)\n",
    "data_tmp = data_inter.head(602578)\n",
    "print('Highest Rojas: ', data_tmp['K_SCORE'].iloc[-1])\n",
    "\n",
    "data_inter.sort_values(by='score_sims', inplace=True)\n",
    "data_tmp = data_inter.head(602578)\n",
    "print('Highest Jacobs: ', data_tmp['score_sims'].iloc[-1])\n",
    "\n",
    "data_inter.sort_values(by='SINGLE', inplace=True)\n",
    "data_tmp = data_inter.head(602578)\n",
    "print('Highest Gonzalez: ', data_tmp['SINGLE'].iloc[-1])\n",
    "\n",
    "#maximum value of prob: 0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48aed7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zoo = pd.read_csv('data/complete_data.csv')\n",
    "\n",
    "filepath = '/Users/jimenagonzalez/research/DSPL/Citizen_science_project/Intersection/data/in_sled2.fits'\n",
    "hdu_list = fits.open(filepath)\n",
    "images = hdu_list[1].data\n",
    "data = pd.DataFrame(hdu_list[2].data)\n",
    "hdu_list.close()\n",
    "\n",
    "data.replace('None', np.nan, inplace=True)\n",
    "data = data.astype({'COADD_OBJECT_ID': int, 'K_RA': float, 'K_DEC': float, 'K_SCORE': float, 'Y3_COADD_OBJECT_ID': int,\n",
    "       'J_RA': float, 'J_DEC': float, 'score_sims': float, 'score_real': float, 'score_both': float, 'G_RA': float,\n",
    "       'G_DEC': float, 'SINGLE': float, 'RING': float, 'SMOOTH': float, 'COMPANIONS': float, 'SDSS_SPIRALS': float,\n",
    "       'DES_SPIRALS': float, 'CROWDED': float, 'ARTIFACTS': float, 'MOST_NEGATIVES': float, 'index': int, 'ra': float,\n",
    "       'dec': float, 'name': str, 'score': float, 'image_sep': float, 'info': str, 'n_img': float, 'flag': str,\n",
    "       'image_conf': str, 'lens_type': str, 'source_type': str, 'contaminant_type': str, 'papers': str})\n",
    "\n",
    "#Getting the images\n",
    "data.set_index('COADD_OBJECT_ID', inplace=True)\n",
    "data_zoo.set_index('COADD_OBJECT_ID', inplace=True)\n",
    "# Reindex 'data' to match the index of 'data_zoo'\n",
    "data = data.reindex(data_zoo.index)\n",
    "# Reset index if needed\n",
    "data.reset_index(inplace=True)\n",
    "data_zoo.reset_index(inplace=True)\n",
    "images = images[data.index]\n",
    "\n",
    "#Using calibrated score:\n",
    "usernames = ['Krojas26', 'sgonzalezloz', 'curiosorus', 'ctortora', 'clarkguilty', 'alejandramelo', 'anupreeta']\n",
    "scores_only = data_zoo[usernames]\n",
    "\n",
    "def remove_min_max(row):\n",
    "    valid_scores = row.dropna().tolist()\n",
    "    if len(valid_scores) <= 2:\n",
    "        # Not enough values to remove min and max\n",
    "        return pd.Series([None] * max(0, len(valid_scores) - 2))\n",
    "    trimmed = sorted(valid_scores)[1:-1]  # Remove lowest and highest\n",
    "    return pd.Series(trimmed, index=[f'user{i+1}' for i in range(len(trimmed))])\n",
    "\n",
    "data_zoo_tmp = data_zoo[usernames].apply(remove_min_max, axis=1)\n",
    "data_zoo_tmp = pd.concat([data_zoo.drop(columns=usernames), data_zoo_tmp], axis=1)\n",
    "\n",
    "new_usernames = ['user1', 'user2', 'user3', 'user4', 'user5']\n",
    "data_zoo_tmp['calib'] = data_zoo_tmp[new_usernames].mean(axis=1)\n",
    "#data_zoo_tmp['calib_std'] = data_zoo_tmp[new_usernames].std(axis=1)\n",
    "#data_zoo_tmp['calib_range'] = data_zoo_tmp[new_usernames].max(axis=1) - data_zoo_tmp[new_usernames].min(axis=1)\n",
    "\n",
    "data_zoo = data_zoo_tmp\n",
    "data_zoo = data_zoo.drop(['average'], axis=1)\n",
    "data_zoo = data_zoo.rename({'calib': 'average'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f837380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1651\n",
      " \n",
      "165\n",
      "63\n",
      "Percentage moderate candidates with all ML scores < 0.8: 38.18%\n",
      " \n",
      "217\n",
      "50\n",
      "Percentage moderate candidates with all ML scores < 0.8: 23.04%\n",
      " \n",
      "61\n",
      "3\n",
      "Percentage moderate candidates with all ML scores < 0.8: 4.92%\n"
     ]
    }
   ],
   "source": [
    "# For most important paragraph. Most high-confidence candidates are recovered by the three works combined.\n",
    "threshold_list = [0.8, 1.2, 1.8]\n",
    "\n",
    "print(len(data_zoo))\n",
    "\n",
    "# Candidates with ambiguous confidence - C\n",
    "print(' ')\n",
    "data_tmp = data_zoo[(data_zoo['average'] >= threshold_list[0]) & (data_zoo['average'] < threshold_list[1])]\n",
    "print(len(data_tmp))\n",
    "print(len(data_tmp[(data_tmp['score_sims'] < 0.8) & (data_tmp['K_SCORE'] < 0.8) & (data_tmp['SINGLE'] < 0.8)]))\n",
    "print('Percentage moderate candidates with all ML scores < 0.8: {:.2f}%'.format(63/165*100))\n",
    "\n",
    "# Candidates with moderate confidence - B\n",
    "print(' ')\n",
    "data_tmp = data_zoo[(data_zoo['average'] >= threshold_list[1]) & (data_zoo['average'] < threshold_list[2])]\n",
    "print(len(data_tmp))\n",
    "print(len(data_tmp[(data_tmp['score_sims'] < 0.8) & (data_tmp['K_SCORE'] < 0.8) & (data_tmp['SINGLE'] < 0.8)]))\n",
    "print('Percentage moderate candidates with all ML scores < 0.8: {:.2f}%'.format(50/217*100))\n",
    "\n",
    "# Candidates with high confidence - A\n",
    "print(' ')\n",
    "data_tmp = data_zoo[(data_zoo['average'] >= threshold_list[2])]\n",
    "print(len(data_tmp))\n",
    "print(len(data_tmp[(data_tmp['score_sims'] < 0.8) & (data_tmp['K_SCORE'] < 0.8) & (data_tmp['SINGLE'] < 0.8)]))\n",
    "print('Percentage moderate candidates with all ML scores < 0.8: {:.2f}%'.format(3/61*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826f99f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1651\n",
      "278\n",
      " \n",
      "192\n",
      "Percentage Jacobs ml score < 0.8: 69.06%\n",
      " \n",
      "134\n",
      "Percentage Rojas ml score < 0.8: 48.20%\n",
      " \n",
      "91\n",
      "Percentage Gonzalez ml score < 0.8: 32.73%\n"
     ]
    }
   ],
   "source": [
    "# Studying the recovery individually: successive works recover more and more candidates\n",
    "\n",
    "print(len(data_zoo))\n",
    "\n",
    "# Candidates with moderate-high confidence\n",
    "data_tmp = data_zoo[data_zoo['average'] >= threshold_list[1]]\n",
    "print(len(data_tmp))\n",
    "\n",
    "print(' ')\n",
    "print(len(data_tmp[data_tmp['score_sims'] < 0.8]))\n",
    "print('Percentage Jacobs ml score < 0.8: {:.2f}%'.format(192/278*100))\n",
    "\n",
    "# Candidates with moderate confidence\n",
    "print(' ')\n",
    "print(len(data_tmp[data_tmp['K_SCORE'] < 0.8]))\n",
    "print('Percentage Rojas ml score < 0.8: {:.2f}%'.format(134/278*100))\n",
    "\n",
    "# Candidates with high confidence\n",
    "print(' ')\n",
    "print(len(data_tmp[data_tmp['SINGLE'] < 0.8]))\n",
    "print('Percentage Gonzalez ml score < 0.8: {:.2f}%'.format(91/278*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc4adc76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "278\n",
      "53\n",
      "Percentage moderate-high candidates with all ML scores < 0.8: 19.06%\n",
      " \n",
      "278\n",
      "225\n",
      "Percentage moderate-high candidates with any ML score >= 0.8: 80.94%\n"
     ]
    }
   ],
   "source": [
    "# Candidates with moderate-high confidence, for conclusion\n",
    "print(' ')\n",
    "data_tmp = data_zoo[data_zoo['average'] >= threshold_list[1]]\n",
    "print(len(data_tmp))\n",
    "print(len(data_tmp[(data_tmp['score_sims'] < 0.8) & (data_tmp['K_SCORE'] < 0.8) & (data_tmp['SINGLE'] < 0.8)]))\n",
    "print('Percentage moderate-high candidates with all ML scores < 0.8: {:.2f}%'.format(53/278*100))\n",
    "\n",
    "print(' ')\n",
    "data_tmp = data_zoo[data_zoo['average'] >= threshold_list[1]]\n",
    "print(len(data_tmp))\n",
    "print(len(data_tmp[(data_tmp['score_sims'] >= 0.8) | (data_tmp['K_SCORE'] >= 0.8) | (data_tmp['SINGLE'] >= 0.8)]))\n",
    "print('Percentage moderate-high candidates with any ML score >= 0.8: {:.2f}%'.format(225/278*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
